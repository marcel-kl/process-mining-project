{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning of Process Representations Using Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from replearn.eventlog import EventLog\n",
    "\n",
    "from replearn.embedding_predict import EmbeddingPredict\n",
    "from replearn.autoencoder import AutoencoderRepresentation\n",
    "from replearn.doc2vec import Doc2VecRepresentation\n",
    "\n",
    "from replearn.clustering import Clustering\n",
    "\n",
    "from replearn.evaluation import Evaluation\n",
    "\n",
    "# !pip install levenshtein\n",
    "from Levenshtein import distance as led\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all possible parameters, abstracted\n",
    "event_log_path = '../logs/'\n",
    "case_attributes = None # auto-detect attributes\n",
    "event_attributes = ['concept:name', 'user'] # use activity name and user\n",
    "true_cluster_label = 'cluster'\n",
    "\n",
    "n_epochs = 25         #[10, 25]\n",
    "n_batch_size = 64\n",
    "n_clusters = 5\n",
    "vector_size = 32      #[2, 3, 4, 8, 16, 32, 64, 128]\n",
    "\n",
    "clustering_method = \"agglomerative\" # [\"k_means\", \"agglomerative\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 2268.19eventlog/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
      "First three: ['small_500_10_20_5_1_1-0.0-1.json.gz']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# noise event logs - self implemented\n",
    "event_logs = {}\n",
    "for i in range(11):\n",
    "    noise = i / 10.0\n",
    "    event_logs[noise] = []\n",
    "\n",
    "# prepare all event log files\n",
    "pattern = r'-(\\d+\\.\\d+)'\n",
    "for file in tqdm(os.listdir(event_log_path), unit='eventlog'):\n",
    "    if os.path.isfile(os.path.join(event_log_path, file)):\n",
    "        match = re.search(pattern, file)\n",
    "        if match:\n",
    "            noise = float(match.group(1))\n",
    "            event_logs[noise].append(file)\n",
    "            \n",
    "print(event_logs.keys())\n",
    "print(\"First three:\", event_logs[0.0][0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trace2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                  | 0/11 [00:00<?, ?noise_level/s]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.29s/event_log]\u001b[A\n",
      "  9%|██████▋                                                                   | 1/11 [00:02<00:23,  2.30s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/event_log]\u001b[A\n",
      " 18%|█████████████▍                                                            | 2/11 [00:04<00:18,  2.09s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.05s/event_log]\u001b[A\n",
      " 27%|████████████████████▏                                                     | 3/11 [00:06<00:16,  2.08s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.19s/event_log]\u001b[A\n",
      " 36%|██████████████████████████▉                                               | 4/11 [00:08<00:14,  2.13s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.66s/event_log]\u001b[A\n",
      " 45%|█████████████████████████████████▋                                        | 5/11 [00:11<00:13,  2.33s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.59s/event_log]\u001b[A\n",
      " 55%|████████████████████████████████████████▎                                 | 6/11 [00:13<00:12,  2.43s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.72s/event_log]\u001b[A\n",
      " 64%|███████████████████████████████████████████████                           | 7/11 [00:16<00:10,  2.53s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.91s/event_log]\u001b[A\n",
      " 73%|█████████████████████████████████████████████████████▊                    | 8/11 [00:19<00:07,  2.66s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.14s/event_log]\u001b[A\n",
      " 82%|████████████████████████████████████████████████████████████▌             | 9/11 [00:22<00:05,  2.81s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.43s/event_log]\u001b[A\n",
      " 91%|██████████████████████████████████████████████████████████████████▎      | 10/11 [00:26<00:03,  3.01s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.42s/event_log]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 11/11 [00:29<00:00,  2.68s/noise_level]\n"
     ]
    }
   ],
   "source": [
    "# init and train Trace2Vec - added noise filtering, loop over all logs, metrics like f-score, statistics to create graph on\n",
    "# statistics saved in google docs excel file in README to utilize further for presentation\n",
    "results_trace2vec= {}\n",
    "for i in range(11):\n",
    "    noise = i / 10.0\n",
    "    results_trace2vec[noise] = []\n",
    "\n",
    "for noise in tqdm(event_logs.keys(), unit=\"noise_level\"):    \n",
    "    for file in tqdm(event_logs[noise], unit='event_log'):\n",
    "        # load file\n",
    "        event_log = EventLog(file, case_attributes=case_attributes, event_attributes=event_attributes, true_cluster_label=true_cluster_label)\n",
    "        event_log.load(event_log_path + file, False)\n",
    "        event_log.preprocess()\n",
    "        \n",
    "        # get sequences from event log as one-hot feature vector\n",
    "        sequences = event_log.event_attributes_flat_onehot_features_2d\n",
    "\n",
    "        doc2vec = Doc2VecRepresentation(event_log)\n",
    "        doc2vec.build_model(append_case_attr=False, append_event_attr=False, vector_size=vector_size, concat=True, epochs=n_epochs)\n",
    "        doc2vec.fit()\n",
    "        \n",
    "        # infer the vector from the model\n",
    "        feature_vector = doc2vec.predict(epochs=50) \n",
    "        \n",
    "        cluster_analysis = Clustering(event_log)\n",
    "        cluster_analysis.cluster(feature_vector, clustering_method, n_clusters, 'cosine')\n",
    "\n",
    "        cluster_result = cluster_analysis.evaluate()\n",
    "        evaluation = Evaluation(event_log)\n",
    "        (fitness, precision, simplicity) = evaluation.evaluate_clusters(n_clusters, cluster_analysis.pred_labels) # Heuristics Miner + 2. Metric\n",
    "        f_score = 2 * (fitness * precision) / (fitness + precision) # idea: fitness <=> recall & precision <=> precision\n",
    "            \n",
    "        results_trace2vec[noise].append({\"f1_bcubed\":cluster_result[2], \"f_score\":f_score, \"fitness\": fitness, \"precision\":precision, \"simplicity\":simplicity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       f1_bcubed    f_score    fitness  precision  simplicity\n",
      "count  11.000000  11.000000  11.000000  11.000000   11.000000\n",
      "mean    0.895001   0.664172   0.724493   0.616018    0.712083\n",
      "std     0.002212   0.192996   0.181781   0.198006    0.122266\n",
      "min     0.888960   0.360574   0.430563   0.303143    0.517412\n",
      "25%     0.894778   0.562183   0.628562   0.504756    0.633898\n",
      "50%     0.896061   0.761703   0.806283   0.733319    0.751487\n",
      "75%     0.896061   0.778172   0.824067   0.738465    0.776049\n",
      "max     0.896467   0.810564   0.906000   0.749821    0.906000\n",
      "---\n",
      "noise: 0.0\n",
      "       f1_bcubed   f_score  fitness  precision  simplicity\n",
      "count   1.000000  1.000000    1.000   1.000000       1.000\n",
      "mean    0.896061  0.810564    0.906   0.733319       0.906\n",
      "std          NaN       NaN      NaN        NaN         NaN\n",
      "min     0.896061  0.810564    0.906   0.733319       0.906\n",
      "25%     0.896061  0.810564    0.906   0.733319       0.906\n",
      "50%     0.896061  0.810564    0.906   0.733319       0.906\n",
      "75%     0.896061  0.810564    0.906   0.733319       0.906\n",
      "max     0.896061  0.810564    0.906   0.733319       0.906\n",
      "---\n",
      "noise: 0.1\n",
      "       f1_bcubed   f_score   fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.000000   1.000000    1.000000\n",
      "mean    0.895858  0.796039  0.867825   0.735223    0.799429\n",
      "std          NaN       NaN       NaN        NaN         NaN\n",
      "min     0.895858  0.796039  0.867825   0.735223    0.799429\n",
      "25%     0.895858  0.796039  0.867825   0.735223    0.799429\n",
      "50%     0.895858  0.796039  0.867825   0.735223    0.799429\n",
      "75%     0.895858  0.796039  0.867825   0.735223    0.799429\n",
      "max     0.895858  0.796039  0.867825   0.735223    0.799429\n",
      "---\n",
      "noise: 0.2\n",
      "       f1_bcubed   f_score   fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.000000   1.000000       1.000\n",
      "mean    0.896467  0.368707  0.470458   0.303143       0.548\n",
      "std          NaN       NaN       NaN        NaN         NaN\n",
      "min     0.896467  0.368707  0.470458   0.303143       0.548\n",
      "25%     0.896467  0.368707  0.470458   0.303143       0.548\n",
      "50%     0.896467  0.368707  0.470458   0.303143       0.548\n",
      "75%     0.896467  0.368707  0.470458   0.303143       0.548\n",
      "max     0.896467  0.368707  0.470458   0.303143       0.548\n",
      "---\n",
      "noise: 0.3\n",
      "       f1_bcubed   f_score   fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.000000   1.000000       1.000\n",
      "mean    0.896247  0.360574  0.438569   0.306131       0.548\n",
      "std          NaN       NaN       NaN        NaN         NaN\n",
      "min     0.896247  0.360574  0.438569   0.306131       0.548\n",
      "25%     0.896247  0.360574  0.438569   0.306131       0.548\n",
      "50%     0.896247  0.360574  0.438569   0.306131       0.548\n",
      "75%     0.896247  0.360574  0.438569   0.306131       0.548\n",
      "max     0.896247  0.360574  0.438569   0.306131       0.548\n",
      "---\n",
      "noise: 0.4\n",
      "       f1_bcubed   f_score   fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.000000   1.000000    1.000000\n",
      "mean    0.893682  0.774199  0.811315   0.740331    0.737148\n",
      "std          NaN       NaN       NaN        NaN         NaN\n",
      "min     0.893682  0.774199  0.811315   0.740331    0.737148\n",
      "25%     0.893682  0.774199  0.811315   0.740331    0.737148\n",
      "50%     0.893682  0.774199  0.811315   0.740331    0.737148\n",
      "75%     0.893682  0.774199  0.811315   0.740331    0.737148\n",
      "max     0.893682  0.774199  0.811315   0.740331    0.737148\n",
      "---\n",
      "noise: 0.5\n",
      "       f1_bcubed   f_score   fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.000000   1.000000    1.000000\n",
      "mean    0.896061  0.364823  0.430563   0.316499    0.517412\n",
      "std          NaN       NaN       NaN        NaN         NaN\n",
      "min     0.896061  0.364823  0.430563   0.316499    0.517412\n",
      "25%     0.896061  0.364823  0.430563   0.316499    0.517412\n",
      "50%     0.896061  0.364823  0.430563   0.316499    0.517412\n",
      "75%     0.896061  0.364823  0.430563   0.316499    0.517412\n",
      "max     0.896061  0.364823  0.430563   0.316499    0.517412\n",
      "---\n",
      "noise: 0.6\n",
      "       f1_bcubed   f_score  fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.00000   1.000000    1.000000\n",
      "mean    0.896061  0.782144  0.81738   0.749821    0.762412\n",
      "std          NaN       NaN      NaN        NaN         NaN\n",
      "min     0.896061  0.782144  0.81738   0.749821    0.762412\n",
      "25%     0.896061  0.782144  0.81738   0.749821    0.762412\n",
      "50%     0.896061  0.782144  0.81738   0.749821    0.762412\n",
      "75%     0.896061  0.782144  0.81738   0.749821    0.762412\n",
      "max     0.896061  0.782144  0.81738   0.749821    0.762412\n",
      "---\n",
      "noise: 0.7\n",
      "       f1_bcubed   f_score   fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.000000   1.000000    1.000000\n",
      "mean    0.893868  0.770128  0.803614   0.739321    0.751487\n",
      "std          NaN       NaN       NaN        NaN         NaN\n",
      "min     0.893868  0.770128  0.803614   0.739321    0.751487\n",
      "25%     0.893868  0.770128  0.803614   0.739321    0.751487\n",
      "50%     0.893868  0.770128  0.803614   0.739321    0.751487\n",
      "75%     0.893868  0.770128  0.803614   0.739321    0.751487\n",
      "max     0.893868  0.770128  0.803614   0.739321    0.751487\n",
      "---\n",
      "noise: 0.8\n",
      "       f1_bcubed   f_score   fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.000000   1.000000    1.000000\n",
      "mean    0.896061  0.761349  0.786667   0.737609    0.753543\n",
      "std          NaN       NaN       NaN        NaN         NaN\n",
      "min     0.896061  0.761349  0.786667   0.737609    0.753543\n",
      "25%     0.896061  0.761349  0.786667   0.737609    0.753543\n",
      "50%     0.896061  0.761349  0.786667   0.737609    0.753543\n",
      "75%     0.896061  0.761349  0.786667   0.737609    0.753543\n",
      "max     0.896061  0.761349  0.786667   0.737609    0.753543\n",
      "---\n",
      "noise: 0.9\n",
      "       f1_bcubed   f_score   fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.000000   1.000000    1.000000\n",
      "mean    0.895689  0.761703  0.806283   0.721794    0.719796\n",
      "std          NaN       NaN       NaN        NaN         NaN\n",
      "min     0.895689  0.761703  0.806283   0.721794    0.719796\n",
      "25%     0.895689  0.761703  0.806283   0.721794    0.719796\n",
      "50%     0.895689  0.761703  0.806283   0.721794    0.719796\n",
      "75%     0.895689  0.761703  0.806283   0.721794    0.719796\n",
      "max     0.895689  0.761703  0.806283   0.721794    0.719796\n",
      "---\n",
      "noise: 1.0\n",
      "       f1_bcubed   f_score   fitness  precision  simplicity\n",
      "count    1.00000  1.000000  1.000000   1.000000    1.000000\n",
      "mean     0.88896  0.755658  0.830755   0.693013    0.789686\n",
      "std          NaN       NaN       NaN        NaN         NaN\n",
      "min      0.88896  0.755658  0.830755   0.693013    0.789686\n",
      "25%      0.88896  0.755658  0.830755   0.693013    0.789686\n",
      "50%      0.88896  0.755658  0.830755   0.693013    0.789686\n",
      "75%      0.88896  0.755658  0.830755   0.693013    0.789686\n",
      "max      0.88896  0.755658  0.830755   0.693013    0.789686\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Statistics\n",
    "\n",
    "# complete\n",
    "complete = []\n",
    "for i in range(11):\n",
    "    complete += results_trace2vec[i/10]\n",
    "complete = pd.DataFrame.from_dict(complete)\n",
    "print(complete.describe())\n",
    "\n",
    "print(\"---\")\n",
    "\n",
    "# noise\n",
    "for i in range(11):\n",
    "    print(f\"noise: {i/10}\")\n",
    "    print(pd.DataFrame.from_dict(results_trace2vec[i/10]).describe())\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## Case2vec (event)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                  | 0/11 [00:00<?, ?noise_level/s]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.83s/event_log]\u001b[A\n",
      "  9%|██████▋                                                                   | 1/11 [00:01<00:18,  1.84s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/event_log]\u001b[A\n",
      " 18%|█████████████▍                                                            | 2/11 [00:03<00:17,  1.92s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.41s/event_log]\u001b[A\n",
      " 27%|████████████████████▏                                                     | 3/11 [00:06<00:17,  2.15s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.27s/event_log]\u001b[A\n",
      " 36%|██████████████████████████▉                                               | 4/11 [00:08<00:15,  2.21s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.59s/event_log]\u001b[A\n",
      " 45%|█████████████████████████████████▋                                        | 5/11 [00:11<00:14,  2.35s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.82s/event_log]\u001b[A\n",
      " 55%|████████████████████████████████████████▎                                 | 6/11 [00:13<00:12,  2.52s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.91s/event_log]\u001b[A\n",
      " 64%|███████████████████████████████████████████████                           | 7/11 [00:16<00:10,  2.65s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.22s/event_log]\u001b[A\n",
      " 73%|█████████████████████████████████████████████████████▊                    | 8/11 [00:20<00:08,  2.84s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.45s/event_log]\u001b[A\n",
      " 82%|████████████████████████████████████████████████████████████▌             | 9/11 [00:23<00:06,  3.04s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.54s/event_log]\u001b[A\n",
      " 91%|██████████████████████████████████████████████████████████████████▎      | 10/11 [00:27<00:03,  3.20s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.95s/event_log]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 11/11 [00:31<00:00,  2.83s/noise_level]\n"
     ]
    }
   ],
   "source": [
    "# init and train Case2vec (event) - added noise filtering, loop over all logs, metrics like f-score, statistics to create graph on\n",
    "# statistics saved in google docs excel file in README to utilize further for presentation\n",
    "results_case2vec_event= {}\n",
    "for i in range(11):\n",
    "    noise = i / 10.0\n",
    "    results_case2vec_event[noise] = []\n",
    "\n",
    "for noise in tqdm(event_logs.keys(), unit=\"noise_level\"):    \n",
    "    for file in tqdm(event_logs[noise], unit='event_log'):\n",
    "        # load file\n",
    "        event_log = EventLog(file, case_attributes=case_attributes, event_attributes=event_attributes, true_cluster_label=true_cluster_label)\n",
    "        event_log.load(event_log_path + file, False)\n",
    "        event_log.preprocess()\n",
    "        \n",
    "        # get sequences from event log as one-hot feature vector\n",
    "        sequences = event_log.event_attributes_flat_onehot_features_2d\n",
    "\n",
    "        doc2vec = Doc2VecRepresentation(event_log)\n",
    "        doc2vec.build_model(append_case_attr=False, append_event_attr=True, vector_size=vector_size, concat=True, epochs=n_epochs)\n",
    "        doc2vec.fit()\n",
    "        \n",
    "        # infer the vector from the model\n",
    "        feature_vector = doc2vec.predict(epochs=50) \n",
    "        \n",
    "        cluster_analysis = Clustering(event_log)\n",
    "        cluster_analysis.cluster(feature_vector, clustering_method, n_clusters, 'cosine')\n",
    "\n",
    "        cluster_result = cluster_analysis.evaluate()\n",
    "        evaluation = Evaluation(event_log)\n",
    "        (fitness, precision, simplicity) = evaluation.evaluate_clusters(n_clusters, cluster_analysis.pred_labels) # Heuristics Miner + 2. Metric\n",
    "        f_score = 2 * (fitness * precision) / (fitness + precision) # idea: fitness <=> recall & precision <=> precision\n",
    "            \n",
    "        results_case2vec_event[noise].append({\"f1_bcubed\":cluster_result[2], \"f_score\":f_score, \"fitness\": fitness, \"precision\":precision, \"simplicity\":simplicity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       f1_bcubed    f_score    fitness  precision  simplicity\n",
      "count  11.000000  11.000000  11.000000  11.000000   11.000000\n",
      "mean    0.893404   0.780099   0.834658   0.732940    0.783374\n",
      "std     0.003447   0.018063   0.034372   0.017797    0.046235\n",
      "min     0.884865   0.742551   0.786472   0.682051    0.742653\n",
      "25%     0.891696   0.771214   0.814213   0.732874    0.758817\n",
      "50%     0.893851   0.782628   0.822214   0.735453    0.765412\n",
      "75%     0.896061   0.789982   0.857787   0.741138    0.797214\n",
      "max     0.896061   0.810564   0.906000   0.750984    0.906000\n",
      "---\n",
      "noise: 0.0\n",
      "       f1_bcubed   f_score  fitness  precision  simplicity\n",
      "count   1.000000  1.000000    1.000   1.000000       1.000\n",
      "mean    0.896061  0.810564    0.906   0.733319       0.906\n",
      "std          NaN       NaN      NaN        NaN         NaN\n",
      "min     0.896061  0.810564    0.906   0.733319       0.906\n",
      "25%     0.896061  0.810564    0.906   0.733319       0.906\n",
      "50%     0.896061  0.810564    0.906   0.733319       0.906\n",
      "75%     0.896061  0.810564    0.906   0.733319       0.906\n",
      "max     0.896061  0.810564    0.906   0.733319       0.906\n",
      "---\n",
      "noise: 0.1\n",
      "       f1_bcubed   f_score   fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.000000   1.000000    1.000000\n",
      "mean    0.896061  0.796875  0.869491   0.735453    0.801429\n",
      "std          NaN       NaN       NaN        NaN         NaN\n",
      "min     0.896061  0.796875  0.869491   0.735453    0.801429\n",
      "25%     0.896061  0.796875  0.869491   0.735453    0.801429\n",
      "50%     0.896061  0.796875  0.869491   0.735453    0.801429\n",
      "75%     0.896061  0.796875  0.869491   0.735453    0.801429\n",
      "max     0.896061  0.796875  0.869491   0.735453    0.801429\n",
      "---\n",
      "noise: 0.2\n",
      "       f1_bcubed   f_score  fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.00000    1.00000       1.000\n",
      "mean    0.896061  0.789328  0.85581    0.73243       0.793\n",
      "std          NaN       NaN      NaN        NaN         NaN\n",
      "min     0.896061  0.789328  0.85581    0.73243       0.793\n",
      "25%     0.896061  0.789328  0.85581    0.73243       0.793\n",
      "50%     0.896061  0.789328  0.85581    0.73243       0.793\n",
      "75%     0.896061  0.789328  0.85581    0.73243       0.793\n",
      "max     0.896061  0.789328  0.85581    0.73243       0.793\n",
      "---\n",
      "noise: 0.3\n",
      "       f1_bcubed   f_score   fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.000000   1.000000    1.000000\n",
      "mean    0.896061  0.779511  0.822214   0.741025    0.810842\n",
      "std          NaN       NaN       NaN        NaN         NaN\n",
      "min     0.896061  0.779511  0.822214   0.741025    0.810842\n",
      "25%     0.896061  0.779511  0.822214   0.741025    0.810842\n",
      "50%     0.896061  0.779511  0.822214   0.741025    0.810842\n",
      "75%     0.896061  0.779511  0.822214   0.741025    0.810842\n",
      "max     0.896061  0.779511  0.822214   0.741025    0.810842\n",
      "---\n",
      "noise: 0.4\n",
      "       f1_bcubed   f_score   fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.000000   1.000000    1.000000\n",
      "mean    0.896061  0.790636  0.859763   0.731798    0.763569\n",
      "std          NaN       NaN       NaN        NaN         NaN\n",
      "min     0.896061  0.790636  0.859763   0.731798    0.763569\n",
      "25%     0.896061  0.790636  0.859763   0.731798    0.763569\n",
      "50%     0.896061  0.790636  0.859763   0.731798    0.763569\n",
      "75%     0.896061  0.790636  0.859763   0.731798    0.763569\n",
      "max     0.896061  0.790636  0.859763   0.731798    0.763569\n",
      "---\n",
      "noise: 0.5\n",
      "       f1_bcubed   f_score   fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.000000   1.000000    1.000000\n",
      "mean    0.891349  0.782628  0.828897   0.741251    0.765412\n",
      "std          NaN       NaN       NaN        NaN         NaN\n",
      "min     0.891349  0.782628  0.828897   0.741251    0.765412\n",
      "25%     0.891349  0.782628  0.828897   0.741251    0.765412\n",
      "50%     0.891349  0.782628  0.828897   0.741251    0.765412\n",
      "75%     0.891349  0.782628  0.828897   0.741251    0.765412\n",
      "max     0.891349  0.782628  0.828897   0.741251    0.765412\n",
      "---\n",
      "noise: 0.6\n",
      "       f1_bcubed   f_score  fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.00000   1.000000    1.000000\n",
      "mean    0.893851  0.783006  0.81788   0.750984    0.761912\n",
      "std          NaN       NaN      NaN        NaN         NaN\n",
      "min     0.893851  0.783006  0.81788   0.750984    0.761912\n",
      "25%     0.893851  0.783006  0.81788   0.750984    0.761912\n",
      "50%     0.893851  0.783006  0.81788   0.750984    0.761912\n",
      "75%     0.893851  0.783006  0.81788   0.750984    0.761912\n",
      "max     0.893851  0.783006  0.81788   0.750984    0.761912\n",
      "---\n",
      "noise: 0.7\n",
      "       f1_bcubed   f_score  fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.00000   1.000000    1.000000\n",
      "mean    0.892044  0.770729  0.80628   0.738181    0.755723\n",
      "std          NaN       NaN      NaN        NaN         NaN\n",
      "min     0.892044  0.770729  0.80628   0.738181    0.755723\n",
      "25%     0.892044  0.770729  0.80628   0.738181    0.755723\n",
      "50%     0.892044  0.770729  0.80628   0.738181    0.755723\n",
      "75%     0.892044  0.770729  0.80628   0.738181    0.755723\n",
      "max     0.892044  0.770729  0.80628   0.738181    0.755723\n",
      "---\n",
      "noise: 0.8\n",
      "       f1_bcubed  f_score   fitness  precision  simplicity\n",
      "count   1.000000  1.00000  1.000000   1.000000    1.000000\n",
      "mean    0.884865  0.76356  0.786472   0.741945    0.745838\n",
      "std          NaN      NaN       NaN        NaN         NaN\n",
      "min     0.884865  0.76356  0.786472   0.741945    0.745838\n",
      "25%     0.884865  0.76356  0.786472   0.741945    0.745838\n",
      "50%     0.884865  0.76356  0.786472   0.741945    0.745838\n",
      "75%     0.884865  0.76356  0.786472   0.741945    0.745838\n",
      "max     0.884865  0.76356  0.786472   0.741945    0.745838\n",
      "---\n",
      "noise: 0.9\n",
      "       f1_bcubed   f_score   fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.000000   1.000000    1.000000\n",
      "mean    0.891349  0.771699  0.813597   0.733904    0.742653\n",
      "std          NaN       NaN       NaN        NaN         NaN\n",
      "min     0.891349  0.771699  0.813597   0.733904    0.742653\n",
      "25%     0.891349  0.771699  0.813597   0.733904    0.742653\n",
      "50%     0.891349  0.771699  0.813597   0.733904    0.742653\n",
      "75%     0.891349  0.771699  0.813597   0.733904    0.742653\n",
      "max     0.891349  0.771699  0.813597   0.733904    0.742653\n",
      "---\n",
      "noise: 1.0\n",
      "       f1_bcubed   f_score   fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.000000   1.000000    1.000000\n",
      "mean    0.893682  0.742551  0.814829   0.682051    0.770742\n",
      "std          NaN       NaN       NaN        NaN         NaN\n",
      "min     0.893682  0.742551  0.814829   0.682051    0.770742\n",
      "25%     0.893682  0.742551  0.814829   0.682051    0.770742\n",
      "50%     0.893682  0.742551  0.814829   0.682051    0.770742\n",
      "75%     0.893682  0.742551  0.814829   0.682051    0.770742\n",
      "max     0.893682  0.742551  0.814829   0.682051    0.770742\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Statistics\n",
    "\n",
    "# complete\n",
    "complete = []\n",
    "for i in range(11):\n",
    "    complete += results_case2vec_event[i/10]\n",
    "complete = pd.DataFrame.from_dict(complete)\n",
    "print(complete.describe())\n",
    "\n",
    "print(\"---\")\n",
    "\n",
    "# noise\n",
    "for i in range(11):\n",
    "    print(f\"noise: {i/10}\")\n",
    "    print(pd.DataFrame.from_dict(results_case2vec_event[i/10]).describe())\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case2vec (event + case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                  | 0/11 [00:00<?, ?noise_level/s]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.26s/event_log]\u001b[A\n",
      "  9%|██████▋                                                                   | 1/11 [00:02<00:22,  2.28s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.49s/event_log]\u001b[A\n",
      " 18%|█████████████▍                                                            | 2/11 [00:04<00:21,  2.41s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.81s/event_log]\u001b[A\n",
      " 27%|████████████████████▏                                                     | 3/11 [00:07<00:20,  2.60s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.91s/event_log]\u001b[A\n",
      " 36%|██████████████████████████▉                                               | 4/11 [00:10<00:19,  2.73s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.85s/event_log]\u001b[A\n",
      " 45%|█████████████████████████████████▋                                        | 5/11 [00:12<00:14,  2.42s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.49s/event_log]\u001b[A\n",
      " 55%|████████████████████████████████████████▎                                 | 6/11 [00:14<00:12,  2.45s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.82s/event_log]\u001b[A\n",
      " 64%|███████████████████████████████████████████████                           | 7/11 [00:18<00:11,  2.90s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.75s/event_log]\u001b[A\n",
      " 73%|█████████████████████████████████████████████████████▊                    | 8/11 [00:24<00:11,  3.81s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.42s/event_log]\u001b[A\n",
      " 82%|████████████████████████████████████████████████████████████▌             | 9/11 [00:27<00:07,  3.70s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.96s/event_log]\u001b[A\n",
      " 91%|██████████████████████████████████████████████████████████████████▎      | 10/11 [00:30<00:03,  3.48s/noise_level]\n",
      "  0%|                                                                                     | 0/1 [00:00<?, ?event_log/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.70s/event_log]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 11/11 [00:33<00:00,  3.06s/noise_level]\n"
     ]
    }
   ],
   "source": [
    "# init and train Case2vec (event+case) - added noise filtering, loop over all logs, metrics like f-score, statistics to create graph on\n",
    "# statistics saved in google docs excel file in README to utilize further for presentation\n",
    "results_case2vec_event_case= {}\n",
    "for i in range(11):\n",
    "    noise = i / 10.0\n",
    "    results_case2vec_event_case[noise] = []\n",
    "\n",
    "for noise in tqdm(event_logs.keys(), unit=\"noise_level\"):    \n",
    "    for file in tqdm(event_logs[noise], unit='event_log'):\n",
    "        # load file\n",
    "        event_log = EventLog(file, case_attributes=case_attributes, event_attributes=event_attributes, true_cluster_label=true_cluster_label)\n",
    "        event_log.load(event_log_path + file, False)\n",
    "        event_log.preprocess()\n",
    "        \n",
    "        # get sequences from event log as one-hot feature vector\n",
    "        sequences = event_log.event_attributes_flat_onehot_features_2d\n",
    "\n",
    "        doc2vec = Doc2VecRepresentation(event_log)\n",
    "        doc2vec.build_model(append_case_attr=True, append_event_attr=True, vector_size=vector_size, concat=True, epochs=n_epochs)\n",
    "        doc2vec.fit()\n",
    "        \n",
    "        # infer the vector from the model\n",
    "        feature_vector = doc2vec.predict(epochs=50) \n",
    "        \n",
    "        cluster_analysis = Clustering(event_log)\n",
    "        cluster_analysis.cluster(feature_vector, 'agglomerative', n_clusters, 'cosine')\n",
    "\n",
    "        cluster_result = cluster_analysis.evaluate()\n",
    "        evaluation = Evaluation(event_log)\n",
    "        (fitness, precision, simplicity) = evaluation.evaluate_clusters(n_clusters, cluster_analysis.pred_labels) # Heuristics Miner + 2. Metric\n",
    "        f_score = 2 * (fitness * precision) / (fitness + precision) # idea: fitness <=> recall & precision <=> precision\n",
    "            \n",
    "        results_case2vec_event_case[noise].append({\"f1_bcubed\":cluster_result[2], \"f_score\":f_score, \"fitness\": fitness, \"precision\":precision, \"simplicity\":simplicity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       f1_bcubed    f_score    fitness  precision  simplicity\n",
      "count  11.000000  11.000000  11.000000  11.000000   11.000000\n",
      "mean    0.471022   0.266240   0.394146   0.216064    0.443401\n",
      "std     0.055325   0.272956   0.316619   0.245014    0.305634\n",
      "min     0.407086   0.007675   0.028000   0.004447    0.032000\n",
      "25%     0.419993   0.058769   0.129700   0.037995    0.181000\n",
      "50%     0.458697   0.144237   0.291988   0.088720    0.426000\n",
      "75%     0.522048   0.498724   0.677313   0.404368    0.703706\n",
      "max     0.545067   0.718850   0.844571   0.664356    0.862000\n",
      "---\n",
      "noise: 0.0\n",
      "       f1_bcubed   f_score   fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.000000   1.000000       1.000\n",
      "mean    0.410871  0.478921  0.844571   0.334222       0.862\n",
      "std          NaN       NaN       NaN        NaN         NaN\n",
      "min     0.410871  0.478921  0.844571   0.334222       0.862\n",
      "25%     0.410871  0.478921  0.844571   0.334222       0.862\n",
      "50%     0.410871  0.478921  0.844571   0.334222       0.862\n",
      "75%     0.410871  0.478921  0.844571   0.334222       0.862\n",
      "max     0.410871  0.478921  0.844571   0.334222       0.862\n",
      "---\n",
      "noise: 0.1\n",
      "       f1_bcubed  f_score   fitness  precision  simplicity\n",
      "count   1.000000  1.00000  1.000000   1.000000        1.00\n",
      "mean    0.429114  0.71885  0.783084   0.664356        0.82\n",
      "std          NaN      NaN       NaN        NaN         NaN\n",
      "min     0.429114  0.71885  0.783084   0.664356        0.82\n",
      "25%     0.429114  0.71885  0.783084   0.664356        0.82\n",
      "50%     0.429114  0.71885  0.783084   0.664356        0.82\n",
      "75%     0.429114  0.71885  0.783084   0.664356        0.82\n",
      "max     0.429114  0.71885  0.783084   0.664356        0.82\n",
      "---\n",
      "noise: 0.2\n",
      "       f1_bcubed   f_score   fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.000000   1.000000       1.000\n",
      "mean    0.409698  0.518528  0.571543   0.474513       0.644\n",
      "std          NaN       NaN       NaN        NaN         NaN\n",
      "min     0.409698  0.518528  0.571543   0.474513       0.644\n",
      "25%     0.409698  0.518528  0.571543   0.474513       0.644\n",
      "50%     0.409698  0.518528  0.571543   0.474513       0.644\n",
      "75%     0.409698  0.518528  0.571543   0.474513       0.644\n",
      "max     0.409698  0.518528  0.571543   0.474513       0.644\n",
      "---\n",
      "noise: 0.3\n",
      "       f1_bcubed   f_score   fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.000000    1.00000       1.000\n",
      "mean    0.407086  0.144237  0.385419    0.08872       0.524\n",
      "std          NaN       NaN       NaN        NaN         NaN\n",
      "min     0.407086  0.144237  0.385419    0.08872       0.524\n",
      "25%     0.407086  0.144237  0.385419    0.08872       0.524\n",
      "50%     0.407086  0.144237  0.385419    0.08872       0.524\n",
      "75%     0.407086  0.144237  0.385419    0.08872       0.524\n",
      "max     0.407086  0.144237  0.385419    0.08872       0.524\n",
      "---\n",
      "noise: 0.4\n",
      "       f1_bcubed   f_score   fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.000000   1.000000       1.000\n",
      "mean    0.444121  0.153006  0.291988   0.103663       0.426\n",
      "std          NaN       NaN       NaN        NaN         NaN\n",
      "min     0.444121  0.153006  0.291988   0.103663       0.426\n",
      "25%     0.444121  0.153006  0.291988   0.103663       0.426\n",
      "50%     0.444121  0.153006  0.291988   0.103663       0.426\n",
      "75%     0.444121  0.153006  0.291988   0.103663       0.426\n",
      "max     0.444121  0.153006  0.291988   0.103663       0.426\n",
      "---\n",
      "noise: 0.5\n",
      "       f1_bcubed   f_score   fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.000000   1.000000        1.00\n",
      "mean    0.458697  0.097483  0.278933   0.059062        0.37\n",
      "std          NaN       NaN       NaN        NaN         NaN\n",
      "min     0.458697  0.097483  0.278933   0.059062        0.37\n",
      "25%     0.458697  0.097483  0.278933   0.059062        0.37\n",
      "50%     0.458697  0.097483  0.278933   0.059062        0.37\n",
      "75%     0.458697  0.097483  0.278933   0.059062        0.37\n",
      "max     0.458697  0.097483  0.278933   0.059062        0.37\n",
      "---\n",
      "noise: 0.6\n",
      "       f1_bcubed   f_score   fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.000000   1.000000       1.000\n",
      "mean    0.489885  0.090445  0.198033   0.058605       0.278\n",
      "std          NaN       NaN       NaN        NaN         NaN\n",
      "min     0.489885  0.090445  0.198033   0.058605       0.278\n",
      "25%     0.489885  0.090445  0.198033   0.058605       0.278\n",
      "50%     0.489885  0.090445  0.198033   0.058605       0.278\n",
      "75%     0.489885  0.090445  0.198033   0.058605       0.278\n",
      "max     0.489885  0.090445  0.198033   0.058605       0.278\n",
      "---\n",
      "noise: 0.7\n",
      "       f1_bcubed   f_score  fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.00000   1.000000    1.000000\n",
      "mean    0.509005  0.668215  0.83643   0.556331    0.763412\n",
      "std          NaN       NaN      NaN        NaN         NaN\n",
      "min     0.509005  0.668215  0.83643   0.556331    0.763412\n",
      "25%     0.509005  0.668215  0.83643   0.556331    0.763412\n",
      "50%     0.509005  0.668215  0.83643   0.556331    0.763412\n",
      "75%     0.509005  0.668215  0.83643   0.556331    0.763412\n",
      "max     0.509005  0.668215  0.83643   0.556331    0.763412\n",
      "---\n",
      "noise: 0.8\n",
      "       f1_bcubed   f_score   fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.000000   1.000000       1.000\n",
      "mean    0.545067  0.027094  0.061367   0.017385       0.084\n",
      "std          NaN       NaN       NaN        NaN         NaN\n",
      "min     0.545067  0.027094  0.061367   0.017385       0.084\n",
      "25%     0.545067  0.027094  0.061367   0.017385       0.084\n",
      "50%     0.545067  0.027094  0.061367   0.017385       0.084\n",
      "75%     0.545067  0.027094  0.061367   0.017385       0.084\n",
      "max     0.545067  0.027094  0.061367   0.017385       0.084\n",
      "---\n",
      "noise: 0.9\n",
      "       f1_bcubed   f_score   fitness  precision  simplicity\n",
      "count   1.000000  1.000000  1.000000   1.000000       1.000\n",
      "mean    0.542606  0.024183  0.056233   0.015404       0.074\n",
      "std          NaN       NaN       NaN        NaN         NaN\n",
      "min     0.542606  0.024183  0.056233   0.015404       0.074\n",
      "25%     0.542606  0.024183  0.056233   0.015404       0.074\n",
      "50%     0.542606  0.024183  0.056233   0.015404       0.074\n",
      "75%     0.542606  0.024183  0.056233   0.015404       0.074\n",
      "max     0.542606  0.024183  0.056233   0.015404       0.074\n",
      "---\n",
      "noise: 1.0\n",
      "       f1_bcubed   f_score  fitness  precision  simplicity\n",
      "count   1.000000  1.000000    1.000   1.000000       1.000\n",
      "mean    0.535092  0.007675    0.028   0.004447       0.032\n",
      "std          NaN       NaN      NaN        NaN         NaN\n",
      "min     0.535092  0.007675    0.028   0.004447       0.032\n",
      "25%     0.535092  0.007675    0.028   0.004447       0.032\n",
      "50%     0.535092  0.007675    0.028   0.004447       0.032\n",
      "75%     0.535092  0.007675    0.028   0.004447       0.032\n",
      "max     0.535092  0.007675    0.028   0.004447       0.032\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Statistics - added by ourselves\n",
    "\n",
    "# complete\n",
    "complete = []\n",
    "for i in range(11):\n",
    "    complete += results_case2vec_event_case[i/10]\n",
    "complete = pd.DataFrame.from_dict(complete)\n",
    "print(complete.describe())\n",
    "\n",
    "print(\"---\")\n",
    "\n",
    "# noise\n",
    "for i in range(11):\n",
    "    print(f\"noise: {i/10}\")\n",
    "    print(pd.DataFrame.from_dict(results_case2vec_event_case[i/10]).describe())\n",
    "    print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
