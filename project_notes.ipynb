{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Process Mining (FSS2023) \n",
    "\n",
    "## Learning of Process Representations Using Recurrent Neural Networks\n",
    "\n",
    "\n",
    "### Tasks\n",
    "- **Clustering**: Since we haven't found any code w.r.t. the Bag-of-activities(BOA), Levenshtein Distance(LED) and  HC(Hybrid Clusterer):\n",
    "    - HC: Use https://link.springer.com/chapter/10.1007/978-3-319-98648-7_17 algorithm (also referred to in the paper)\n",
    "    - LED: Simple algorithm; simple import: `from leven import levenshtein` or add as `metric` parameter into clustering algorithm\n",
    "    - BOA: Like Bag of Words (for NLP) but with activities?\n",
    "\n",
    "###### Q1: Should we also replicate the other approaches, since their approach focuses on the RNN approach?\n",
    "\n",
    "---\n",
    "\n",
    "- **Metrics**:\n",
    "    - B-cubed: Allows to evaluate clustering without labeling any clusters (b3.py)\n",
    "        - Idea: calculate Precision & Recall and average their sum\n",
    "    - Fitness, Precision, Simplicity (evaluation.py)\n",
    "   \n",
    "---\n",
    "\n",
    "- **Dependencies**: We have noted that since the code was written in mid-2020, packages have changed their APIs:\n",
    "    - pm4py: install pm4py package that is released during 16. July  2020 and 6. December 2020 - version 1.4.0 seems to work well\n",
    "\n",
    "---\n",
    "\n",
    "- **Data Transformation**:\n",
    "    - How does it work (preprocess & structure of event log)\n",
    "    - How to add new (own) data?\n",
    "        - The log file is only one of many of the downloaded data sets => How to train all?\n",
    "        - Q: ==> Did the author just train on ONE of the dataset samples? (since the data is enough there?)\n",
    "    - They only linked the synethetic logs and not the 2 real event logs \n",
    "        - BPIC 2015: https://data.4tu.nl/collections/BPI_Challenge_2015/5065424/1\n",
    "        - BPIC 2019: https://icpmconference.org/2019/icpm-2019/contests-challenges/bpi-challenge-2019/\n",
    "\n",
    "###### Q2. We assume that besides the linked synthetic data sets, we also have to apply the approaches on both real data sets?\n",
    "\n",
    "---\n",
    "General steps:\n",
    "\n",
    "- Goal: Replicate the paper and if successful adapt the approach e.g., on new data, which works very well in our case since we want to automatically create vector representations that are then used to build process models from (new) event logs.\n",
    "- ....  (GOOGLE DOC)\n",
    "\n",
    "###### Q3. We haven't seen a predefined seed, therefore we presume clustering results to possibly slightly change\n",
    "###### Q4. Does the RNN \"overfit\" in some sense, as the model is trained and evaluated on the same data. (So that we can predit known case attributes). However, since we are only interested on the internal vector representation for that one dataset (must train the model on the data to obtain it everytime for a new data set), this seems fine...\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Abstract:\n",
    "- In process mining, many tasks use a simplified **representation** of a single **case** to perform tasks like trace clustering, anomaly detection, or subset identification.\n",
    "    - Emb(case)\n",
    "    - Capture the control-flow and the context\n",
    "- RNN architecture for representational learning to *automate the generation of the representations*\n",
    "    - supervised training\n",
    "- Evaluation: **trace clustering**!\n",
    "\n",
    "Introduction:\n",
    "- Problem: It is not easy to incorporate the control-flow & **context** into a *single representation*\n",
    "    - Emb(case); case with control-flow & context\n",
    "- Supervised training of RNN with sequence of activities (control-flow) and event, and case attributes (context)\n",
    "    - Trains to predict the contextual factors (and not to predict the next activitiy)\n",
    "    - Force the RNN to learn the characteristics of a case incl. the context in a dense form\n",
    "    - Like BINet: First read complete case, transform it into internal representation, then predict the case attributes\n",
    "- Result: Highly dense vector representation (hidden state of RNN) for each case\n",
    "    - Can be used for other process mining tasks\n",
    "    - evaluate on trace clustering w.r.t. fitness, precision, and simplicity\n",
    "\n",
    "Representation Learning:\n",
    "- Context captures both event and case attributes => incorporating them (additionally to control-flow) into case representation is often hard and time-consuming\n",
    "- Use the internal state (c/h = thought vector?) of the RNN to obtain case representaiton\n",
    "    - internal state = input in compact form to predict the output\n",
    "    - internal state acts as internal representation\n",
    "    - used for clustering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
